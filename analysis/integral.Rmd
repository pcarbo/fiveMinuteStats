---
title: Every Bayesian computation is an integral (or a sum)
author: 
  name: Matthew Stephens
  affiliation: University of Chicago
date: December 29, 2025
output:
  pdf_document:
    keep_tex: false
    latex_engine: pdflatex
    template: readable.tex
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: single
graphics: yes
endnote: no
---

See [here][pdf_version] for a PDF version of this vignette.

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,fig.align = "center")
```

Prerequisites
=============

Be familiar with basic probability and Bayesian calculations.

Overview
========

The goal here is simply to point out that everything you want to
compute in Bayesian calculations is an integral.

Examples
========

Consider inference for a parameter $\theta$ from data $D$.
The posterior distribution of $\theta$ is given by Bayes Theorem:
$$
p(\theta \mid D) = \frac{p(\theta) \, p(D \mid \theta)}{p(D)}.
$$
First note that the denominator $p(D)$ is an integral:
$$
p(D) = \textstyle \int p(D \mid \theta) \, p(\theta) \, d\theta.
$$
Now suppose we want to estimate $\theta$ by its posterior mean.
This is
$$
E(\theta \mid D) = \textstyle \int \theta \, p(\theta \mid D) \, d\theta.
$$
And if we want to find a 90% posterior credible interval for $\theta$,
then we want to find $A$ and $B$ such that $\Pr(\theta \in [A,B] \mid D)
= 0.9$. The LHS of this is
$$
\Pr(\theta \in [A,B] \mid D) =
\textstyle
\int \mathbb{I}(\theta \in [A,B]) \, p(\theta \mid D) \,
d\theta,
$$
where $\mathbb{I}(E)$ denotes the indicator function for the event
$E$, which takes the value 1 if $E$ is true, and $0$ otherwise.

Examples: discrete
==================

Of course, if $\theta$ is discrete then the integrals above all become
sums. For example,
$$
E(\theta \mid D) = \sum_n \theta_n \Pr(\theta = \theta_n \mid D),
$$
where $\theta_1, \theta_2, \dots$ are the possible values for $\theta$.

Summary
=======

Pretty much all the things you want to compute when doing Bayesian
inference are integrals (or sums) of one kind or another...

If you are computing 1-dimensional integrals, then numerical methods
are often useful. For example, Simpson's Rule, Gaussian Quadrature.
These can also work in 2-dimensions, and maybe even 3 or 4.

Other simple methods that can work for low dimensions include naive
Monte Carlo and Importance Sampling. Also Laplace's method.

For higher dimensions, we resort to other methods such as Markov chain
Monte Carlo (MCMC).

[pdf_version]: https://github.com/pcarbo/fiveMinuteStats/blob/master/docs/integral.pdf
