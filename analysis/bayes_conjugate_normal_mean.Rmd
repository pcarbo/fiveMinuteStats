---
title: Bayesian computations for the mean of a normal distribution
author: 
  name: Matthew Stephens
  affiliation: University of Chicago
date: January 12, 2026
output:
  pdf_document:
    keep_tex: false
    latex_engine: pdflatex
    template: readable.tex
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: single
graphics: yes
endnote: no
---

See [here][pdf_version] for a PDF version of this vignette.

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,fig.align = "center")
```

Introduction
============

We consider computing the posterior distribution of $\mu$ given data
$X \sim N(\mu,\sigma^2)$, where $\sigma^2$ is known.  You should be
familiar with the idea of a [conjugate prior][bayes_conjugate].

Preliminaries
=============

This problem is really about algebraic manipulation.

There are two tricks to making the algebra a bit simpler. The first is
to work with the precision $\tau=1/\sigma^2$ instead of the variance
$\sigma^2$. So consider $X \sim N(\mu,1/\tau)$.

The second trick is to rewrite the normal density slightly.
First, let us recall the usual form for the normal density.
If $Y \sim N(\mu, 1/\tau)$, then it has density
$$
p(y) = (\tau/2\pi)^{1/2} \textstyle \exp(-\frac{\tau}{2} (y-\mu)^2).
$$

We can rewrite this as
$$
p(y) \propto \textstyle
\exp(-\frac{1}{2}\tau y^2 + \tau \mu y),
$$
or equivalently
$$
p(y) \propto \textstyle \exp(-\frac{1}{2}Ay^2 +  y),
$$
where $A = \tau$ and $B=\tau \mu$. 

Thus, if $p(y) \propto \exp(-\frac{1}{2}Ay^2 + By)$, then $Y$ is
normal with precision $\tau= A$ and mean $\mu= B/A$.

Posterior calculation
=====================

Now let's go back to the problem. Assume we observe a single data
point, $X \sim N(\mu, 1/\tau)$, with $\tau$ known, and our goal is to
do Bayesian inference for the mean $\mu$.

As we will see, the conjugate prior for the mean $\mu$ turns out to be
a normal distribution. So we will assume the prior
$$
\mu \sim N(\mu_0, 1/\tau_0).
$$
(Here, the "0" subscripts are used to indicate that $\mu_0, \tau_0$
are parameters in the prior.)

Now we can compute the posterior density for $\mu$ using Bayes Theorem:
$$
\begin{aligned}
p(\mu \mid X) &\propto p(X \mid \mu) \, p(\mu) \\
&\propto \textstyle \exp[-\frac{\tau}{2}(X-\mu)^2] \times
\exp[-\frac{\tau_0}{2} (\mu-\mu_0)^2] \\
&\propto \textstyle
\exp[-\frac{1}{2}(\tau+\tau_0)\mu^2 + (X\tau + \mu_0\tau_0)\mu].
\end{aligned}
$$
Using the result in "Preliminaries", we obtain
$$
\mu \mid X \sim N(\mu_1, 1/\tau_1),
$$
where
$$
\begin{aligned}
\tau_1 &= \tau + \tau_0 \\
\mu_1 &= \frac{X\tau+\mu_0 \tau_0}{\tau + \tau_0}.
\end{aligned}
$$

Interpretation
==============

Although the algebra may look a little messy the first time you see
it, in fact this result has some simple and elegant interpretations.

First, let us deal with the precision.  Note that the posterior
precision ($\tau_1$) is the sum of the data precision ($\tau$) and the
prior precision ($\tau_0$). This makes sense: the more precise your
data, and the more precise your prior information, the more precise
your posterior information. This also means that the data always
improve your posterior precision over the prior preccision:
noisy data (small $\tau$) improves it only a little,
whereas precise data improves it a lot.

Second, let us deal with the mean.
We can rewrite the posterior mean as
$$
\mu_1 = w X + (1-w) \mu_0,
$$
where $w = \tau/(\tau+\tau_0)$.  Thus $\mu_1$ is a *weighted average*
of the data $X$ and the prior mean $\mu_0$.  And the weights $w, 1 -
w$ depend on the relative precision of the data and the prior: if the
data are precise compared with the prior ($\tau \gg \tau_0$), the
weight $w$ will be close to 1 and the posterior mean will be close to
the data; if the data are imprecise compared with the prior ($\tau
\ll \tau_0$), the weight $w$ will be close to zero and the posterior
mean will be close to the prior mean.

You can see a visual illustration of this result in [this shiny
app][shiny_normal_example].

[pdf_version]: https://github.com/pcarbo/fiveMinuteStats/blob/master/docs/bayes_conjugate_normal_mean.pdf
[bayes_conjugate]: https://pcarbo.github.io/fiveMinuteStats/bayes_conjugate.html
[shiny_normal_example]: https://pcarbo.github.io/fiveMinuteStats/shiny_normal_example.html
